{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# OPPGAVE 1 KLASSIFISERING\n",
    "\n",
    "#### Bruk datasettet Universalbank.csv og bygg klassifiseringsmodeller som gir en binær prediksjon om en kunde vil akseptere et lån fra Universal Bank eller ikke."
   ],
   "id": "5080ae6d95bb1b71"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-06T14:35:27.734511Z",
     "start_time": "2025-11-06T14:35:23.888909Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 1 Filopplastning\n",
    "\n",
    "### 1.1 Lesing\n",
    "Her har jeg laget en egen variabel for file path, slik at hvis jeg bruker den flere steder og den senere skulle endre til et annet datasett, så blir endringen lettere. \n",
    "\n",
    "### 1.2 Visning\n",
    "Jeg printer også toppradene til dataene/tabellen for å få et overblikk over hvilke ulike typer data vi har å jobbe med. Det gjør det blandt annet lettere for meg å se om det er noen unødvendige kolonner med data som kan fjernes, ser at det ikke mangler essensielle kolonner (som \"personal loan\" i denne oppgaven)."
   ],
   "id": "74ad57a3b1c42019"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T14:35:29.897353Z",
     "start_time": "2025-11-06T14:35:29.861461Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1.1 Lesing\n",
    "file_path = 'Data/UniversalBank.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 1.2 Vising\n",
    "print(\"\\n Tabell første rader\")\n",
    "print(df.head())"
   ],
   "id": "90cc9d50bb6c0d5a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Tabell første rader\n",
      "   ID  Age  Experience  Income  ZIP Code  Family  CCAvg  Education  Mortgage  \\\n",
      "0   1   25           1      49     91107       4    1.6          1         0   \n",
      "1   2   45          19      34     90089       3    1.5          1         0   \n",
      "2   3   39          15      11     94720       1    1.0          1         0   \n",
      "3   4   35           9     100     94112       1    2.7          2         0   \n",
      "4   5   35           8      45     91330       4    1.0          2         0   \n",
      "\n",
      "   Personal Loan  Securities Account  CD Account  Online  CreditCard  \n",
      "0              0                   1           0       0           0  \n",
      "1              0                   1           0       0           0  \n",
      "2              0                   0           0       0           0  \n",
      "3              0                   0           0       0           0  \n",
      "4              0                   0           0       0           1  \n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 2 Kvalitetssjekk\n",
    "\n",
    "For at modellene skal bli riktige/best mulig, må man sjekke at man har riktige og gode data. \n",
    "\n",
    "### 2.1 Fordeling\n",
    "Her sjekker jeg om det finnes både ja og nei til lån og hvordan andelene er fordelt. I dette datasettet ser vi at det er 10% som er Ja/1 og retserende er nei/0. Denne skjeivfordelingen kan skape problemer ved trening og testing om man ikke tar hennsyn til det. Så denne delen av koden er for å oppdage dette slik at vi ikke ignorerer det. \n",
    "\n",
    "### 2.2 Kvalitetssjekk målvariabel\n",
    "Videre vil jeg sjekke at vi har det vi trenger fra målvariabelen vår. Vi skal finne ut av om en person får lån eller ikke, som vil si at målvariabelen blir \"Personal Loan\". Her vil jeg sjekke om alle dataene er oppgitt likt. Om noen data skulle mangle eller være ugjyldige, eller si \"yes\" isteden for 1 eller liknende, må disse dataene fjernes eller rettes på før vi går videre på treningen. Vi kan ikke bare fjerne hele kolonnen og må ta ekstra hennsyn til denne, da hele treningen avhenger av denne kolonnen/dataene. Jeg sjekket målvariablene for seg da de er viktige, slik at det skal være lettere å fikse opp i eventuelle feil, samt gjøre det lettere å huske på.\n",
    "\n",
    "### 2.3 Kvalitetssjekk variabler\n",
    "De andre ataene variablene er ikke nødvendighvis like avgjørende for at modellen skal fungere godt og sees derfor på separat fra målvariabelen. Om det skulle være feil eller mangler ved disse kan man finne løsninger avhengig av feilen. Men jeg velger å sjekke dette for å se hvor det eventuellt ligger feil for å kunne avgjøre om dette er noe som kan påvirke dataene og må endres på. \n",
    "\n",
    "### 2.4 Datatyper\n",
    "Jeg sjekker datatypene i hver kolonne for å få overordnet kontroll og få inblikk i hvordan behandle dataene videre. Eks kan det være greit å vite datatypen til hvert felt, men også være klar over dersom ett enkelt felt inneholder flere datatyper. Dersom et felt eks skriver \"ja\" og \"nei\" i strenger, vil jeg kanskje endre dette til binær. Om det eks er en type variabel som oppgir dataene som string \"ja\" i noen data og som \"1\" i binær andre, så må jeg også ta hennsyn til dette og gjøre de like. Altså vil jeg skape overordnet kontroll over hva slags data jeg sitter med, slik jeg kan tilpasse dataene etter hvordan jeg ønsker/trenger dem til læringen. \n",
    "\n",
    "### 2.5 Duplikater\n",
    "Duplikater kan skape problemer og bør fjernes. I denne koden ser jeg ikke umiddelbare ulemper med duplikatene, men jeg ser heller ingen fordel, og hadde derfor fjernet dem om det hadde fantes. Jeg mistenker at det poensiellt kunne skapt bias i løsningen med trær f.eks. "
   ],
   "id": "87132675d270a016"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T14:35:34.370437Z",
     "start_time": "2025-11-06T14:35:34.346134Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# 2.1 Fordeling\n",
    "print(\"\\n Antall per klasse av målvariabel\")\n",
    "print(df['Personal Loan'].value_counts())\n",
    "\n",
    "print(\"\\n Andel per klasse i poosent (%) av målvariabel\")\n",
    "print(df['Personal Loan'].value_counts(normalize=True))\n",
    "\n",
    "# 2.2 Kvalitetssjekk målvariabel\n",
    "print(\"\\n Unike verdier av målvariabel\")\n",
    "print(df['Personal Loan'].unique())\n",
    "\n",
    "print(\"\\n Antall manglende verdier av målvariabel\")\n",
    "print(df['Personal Loan'].isna().sum()) \n",
    "\n",
    "# 2.3 Kvalitetssjekk variabler\n",
    "print(\"\\nManglende verdier per kolonne:\")\n",
    "print(df.isna().sum())\n",
    "\n",
    "# 2.4 Datatyper\n",
    "print(\"\\nDatatyper per kolonne:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# 2.5 Duplikater\n",
    "print(\"\\n Antall duplikatrader:\", df.duplicated().sum())\n",
    "df = df.drop_duplicates().reset_index(drop=True)"
   ],
   "id": "b6e7778b8e89268",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Antall per klasse av målvariabel\n",
      "Personal Loan\n",
      "0    4520\n",
      "1     480\n",
      "Name: count, dtype: int64\n",
      "\n",
      " Andel per klasse i poosent (%) av målvariabel\n",
      "Personal Loan\n",
      "0    0.904\n",
      "1    0.096\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      " Unike verdier av målvariabel\n",
      "[0 1]\n",
      "\n",
      " Antall manglende verdier av målvariabel\n",
      "0\n",
      "\n",
      "Manglende verdier per kolonne:\n",
      "ID                    0\n",
      "Age                   0\n",
      "Experience            0\n",
      "Income                0\n",
      "ZIP Code              0\n",
      "Family                0\n",
      "CCAvg                 0\n",
      "Education             0\n",
      "Mortgage              0\n",
      "Personal Loan         0\n",
      "Securities Account    0\n",
      "CD Account            0\n",
      "Online                0\n",
      "CreditCard            0\n",
      "dtype: int64\n",
      "\n",
      "Datatyper per kolonne:\n",
      "ID                      int64\n",
      "Age                     int64\n",
      "Experience              int64\n",
      "Income                  int64\n",
      "ZIP Code                int64\n",
      "Family                  int64\n",
      "CCAvg                 float64\n",
      "Education               int64\n",
      "Mortgage                int64\n",
      "Personal Loan           int64\n",
      "Securities Account      int64\n",
      "CD Account              int64\n",
      "Online                  int64\n",
      "CreditCard              int64\n",
      "dtype: object\n",
      "\n",
      " Antall duplikatrader: 0\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 3. Rensing og inndeling\n",
    "\n",
    "Ut ifra funnene i kvalitetssjekken så renser jeg dataene. I kvalitetssjekken fant jeg ingen store feil i dataene. \n",
    "\n",
    "### 3.1 Rensing\n",
    "Det er i midlertid visse ting som bør renses av logiske grunner. \n",
    "- ID vil ikke ha noe med om en person får lån eller ikke, og skal derfor fjernes/droppes. \n",
    "- Hvor man bor burde logisk sett heller ikke ha noe med om man får lån eller ikke, derfor fjerner/dropper jeg den også. Det kan finnes scenarier hvor dette har noe å si, men da må man kode mer rundt for å ta i bruk denne variabelen.\n",
    "\n",
    "### 3.2 Inndeling\n",
    "Det deles videre inn i X (features) og y (målvariabel). Målvariabelen fjernes fra features fordi vi vil unngå at man \"ser\" fasiten under trening, men kun bruker den for å justere modellen etter å ha truffet/bommet. \n",
    "\n",
    "### 3.3 Train/test fordeling\n",
    "Vi bruker stratify for å bevare samme prosentfordeling mellom testdataene og treningsdataene, slik at det ikke skal komme feil som følge av skeivfordeling. Vi printer deretter ut hvor godt fordelt det er for å sjekke at alt gikk riktig. Dataene deles i 80/20 da vi har nok data å trene på til å ikke måtte gå opp til 90/10, men det kan hende at også 70/30 kan være en fin fordeling da vi har god mengde med data. \n"
   ],
   "id": "ad4ec5b88aa9289e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T07:57:49.176878Z",
     "start_time": "2025-11-07T07:57:49.113201Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 3.1 Rensing. \n",
    "cols_to_drop = ['ID', 'ZIP Code']\n",
    "df_clean = df.drop(columns=cols_to_drop).copy()\n",
    "\n",
    "# 3.2 Inndeling\n",
    "X = df_clean.drop(columns=['Personal Loan'])\n",
    "y = df_clean['Personal Loan']\n",
    "\n",
    "# 3.3 Train/test fordeling\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.20,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"\\n Andel lån akseptert :\")\n",
    "print(\"Total :\", y.mean().round(3))\n",
    "print(\"Train :\", y_train.mean().round(3))\n",
    "print(\"Test  :\", y_test.mean().round(3))\n",
    "\n"
   ],
   "id": "cfb7d1810b67291f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Andel lån akseptert :\n",
      "Total : 0.096\n",
      "Train : 0.096\n",
      "Test  : 0.096\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 4. Valg av modell\n",
    "\n",
    "Da vi vet utfallet på dataene vi jobber med, jobber vi med suprivised learning, hvor vi bruker utfallet som fasit for å sjekke om prediksjonene er riktig. Altså har vi en målestokk og faktisk fasit på hvor godt modellen treffer. \n",
    "\n",
    "Noen modeller som ble vurdert var:\n",
    "\n",
    "1. Logistisk regresjon\n",
    "Denne modellen er lett og vanlig på datasett hvor målvariabelen er ja/nei. Man kan si for hver kolonne, så øker eller minker sannsynligheten for at utfallet går mot ja eller nei, altså over eller under en gitt grense/strek. Denne er best når sammenhengen mellom variabler og utfall er linjær. Jeg vil tro at om en person har god inntekt, så vil beslutningen naturlighvis lene mer mot et ja. På samme måte som hvis personen allerede har mye lån, så leder naturlig beslutningen mer mot nei. Altså øker/minker sannsynligheten for et gitt utfall, ved hvert utsagn/felt. Denne sliter mer når det er ting som ikke alltid har en like åpenbar vekt mellom ja/nei. \n",
    "\n",
    "2. Bessutningstre\n",
    "Et beslutningstre går gjennom variablene en og en og lager ja/nei-splitt. Problemet er at det lett kan overfitte. Vi har mange tallfelt og mange mulige terskler, så treet kan ende opp med veldig spesielle regler som bare passer en liten gjeng i treningsdata og ikke nødvendighvis passer nye kudner så godt.  Jo flere mulige splitt, desto flere grener, og da blir modellen spiss og mindre robust. I tillegg er \"ja til lån\" en liten gruppe. Da kan treet fort lage egne smale regler for å fange disse få tilfellene, i stedet for å lære det generelle mønsteret. Den er bedre enn lineær ved at den kan finne sammenheng i kombinasjoner. Eks 1 betyr ja, 2 betyr nei i lineær, men kanskje kombinasjonen av begge vekter mot nei, og dette kan denne plukke opp på. \n",
    "\n",
    "\n",
    "3. Randome Forest\n",
    "Denne modellen er også mer vanlig i supervised modeller (trenger X og y). Random Forest består av mange små beslutningstrær som hver får litt tilfeldige data/variabler. Hvert tre stemmer, og flertallet bestemmer. Fordelen vs. ett tre er at veldig spissede (overtilpassede) regler ikke får dominere, fordi skogen jevner ut disse utslagene. Resultatet blir ofte mer stabil modell med mindre overfitting. \n",
    "\n",
    "4. KNN\n",
    "KNN regner ut avstand mellom punkter og bruker verdiene i feltene til å beregne disse avstandene. Denne ryker da, fordi vi har felter med 1 og 0, og vi har felter som er høye nummer som lønn. Avstanden vil derfor bli beregnet veldig i fordel til visse felter, og kan ta for lite hennsyn til de andre feltene som kanskje er avgjørende. Man kunne potensiellt også endret på formatet på dataene om man ville bruke denne ved å kategorisere lønn i grupper f.eks, men dette så jeg som mer komplisert enn det som var nødvendig for opppgaven. \n",
    "\n",
    "5. NN\n",
    "Nevrale nett er også mulig, men blir for komplisert i denne oppgaven. En av fordelene med NN er at man ikke trenger å vite svaret for å kunne finne mønster, men når man har mønster så er det lettere å bruke en metode som utnytter dette. \n",
    "\n",
    "En siste mulig løsning er å kombinere flere modeller om man skulle øsnke det. \n",
    "\n",
    "Valget ble derfor å gå med en modell som bruker Logistisk Regresjon, og en som bruker Beslutningstre.\n"
   ],
   "id": "c5e6d164e1626497"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 5. Modell 1, Logistisk Regresjon\n",
    "\n",
    "### 5.1 Trening\n",
    "Siden dataene våre har stor ubalanse (få \"ja\") brukers det class_weight = \"balanced\" fordi modellen ellers \"jukser\" ved å nesten alltid gjette flertallet (nei). Balanced gjør straffen for å bomme på den lille gruppen (ja) større, og straffen for å bomme på den store gruppen (nei) mindre. Dette gjør at modellen må jobbe mer for å finne den lille gruppen, i stedet for å ignorere dem for å få høy (men meningsløs) treffsikkerhet.\n",
    "\n",
    "### 5.2 Prediksjoner\n",
    "Denne delen gjør to ting. Først så gir den en avgjørelse ja (1) eller nei (0). Deretter sjekkes det hvor sannsynlig det er at dette utfallet er riktig. Altså kan utfallet være ja, men kun med 60% sannsynlighet. Den ene brukes kun for å se svaret, og den andre for å evaluere treffsikkerheten. \n",
    "\n",
    "### 5.3 Evaluering\n",
    "I evalueringen ser vi på :\n",
    "1. Nøyaktigheten: Som forteller oss om antall riktige vi har fått totalt\n",
    "2. Presisjon: som sjekker på hvor mange av \"ja\" dataene er faktisk riktige. True positive (TP)\n",
    "3. Recall: Hvor mange av ja kundene den klarer å finne\n",
    "4. F1 : Balanserer presisjon og recall (Da disse påvirker hverandre)\n",
    "5. ROC-AUC : Sier noe om hvor godt modellen kan skille mellom ja/nei, uansett terskel. \n",
    "\n",
    "\n",
    "### 5.4 Forvirringsmatrise/Confusion matrix\n",
    "Tilslutt valgte jeg å ha med en matrise som viser noe om nøyaktigheten. Det er greit å vite hvor mange \"false positives\" (FP) og \"False negatives\" (FN) man har, for å kunne se hva modellen gjør."
   ],
   "id": "9769b5454e55eed1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T07:58:00.487997Z",
     "start_time": "2025-11-07T07:57:59.713609Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "# 5.1 Trening\n",
    "logit = LogisticRegression(class_weight='balanced', max_iter=1000 )\n",
    "logit.fit(X_train, y_train)\n",
    "\n",
    "# 5.2 Prediksjoner\n",
    "\n",
    "y_pred = logit.predict(X_test)\n",
    "y_prob = logit.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# 5.3 Evaluering todo Evaluer (ikke bare accuracy pga. ubalanse), hva vil dette si?\n",
    "print(\"\\n Evaluering/Resultater\")\n",
    "print(\"Accuracy :\", round(accuracy_score(y_test, y_pred), 3))\n",
    "print(\"Precision:\", round(precision_score(y_test, y_pred), 3))\n",
    "print(\"Recall   :\", round(recall_score(y_test, y_pred), 3))\n",
    "print(\"F1-score :\", round(f1_score(y_test, y_pred), 3))\n",
    "print(\"ROC-AUC  :\", round(roc_auc_score(y_test, y_prob), 3))\n",
    "\n",
    "# 5.4 Confusion matrix (TP/FP/FN/TN)\n",
    "print(\"\\nConfusion matrix (TN, FP; FN, TP):\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ],
   "id": "605ed2185cc73db9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Evaluering/Resultater\n",
      "Accuracy : 0.896\n",
      "Precision: 0.479\n",
      "Recall   : 0.938\n",
      "F1-score : 0.634\n",
      "ROC-AUC  : 0.962\n",
      "\n",
      "Confusion matrix (TN, FP; FN, TP):\n",
      "[[806  98]\n",
      " [  6  90]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\melo1\\OneDrive - NTNU\\Desktop\\Alle semester\\5 semester\\Big Data\\DataScienceArbeidskrav\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 6. Modell 2, Randome Tree\n",
    "\n",
    "### 6.1 Trening\n",
    "Koden lager mange små trær og trener dem på litt forskjellige biter av data. Hvert tre lærer sine egne enkle regler. Når alle trærne er trent, er modellen klar til å stemme på svar senere. Poenget i koden er altså: bygg mange trær, la dem lære hver for seg, og gjør dem klare til felles avstemning.\n",
    "\n",
    "### 6.2 Prediksjoner\n",
    "Denne delen gjør to ting. Først så gir den en avgjørelse ja (1) eller nei (0). Deretter sjekkes det hvor sannsynlig det er at dette utfallet er riktig. Altså kan utfallet være ja, men kun med 60% sannsynlighet. Den ene brukes kun for å se svaret, og den andre for å evaluere treffsikkerheten. \n",
    "\n",
    "### 6.3 Evaluering\n",
    "I evalueringen ser vi på :\n",
    "1. Nøyaktigheten: Som forteller oss om antall riktige vi har fått totalt\n",
    "2. Presisjon: som sjekker på hvor mange av \"ja\" dataene er faktisk riktige. True positive (TP)\n",
    "3. Recall: Hvor mange av ja kundene den klarer å finne\n",
    "4. F1 : Balanserer presisjon og recall (Da disse påvirker hverandre)\n",
    "5. ROC-AUC : Sier noe om hvor godt modellen kan skille mellom ja/nei, uansett terskel. \n",
    "\n",
    "\n",
    "### 6.4 Forvirringsmatrise/Confusion matrix\n",
    "Tilslutt valgte jeg å ha med en matrise som viser noe om nøyaktigheten. Det er greit å vite hvor mange \"false positives\" (FP) og \"False negatives\" (FN) man har, for å kunne se hva modellen gjør."
   ],
   "id": "f7db57673185cbeb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T14:04:30.534484Z",
     "start_time": "2025-11-07T14:04:04.729893Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (accuracy_score, precision_score,\n",
    "                             recall_score, f1_score, roc_auc_score,\n",
    "                             confusion_matrix)\n",
    "\n",
    "# 6.1 Trening\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    class_weight='balanced_subsample',\n",
    "    random_state=42,\n",
    "    n_jobs=-1 \n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# 6.2 Prediksjon\n",
    "y_pred = rf.predict(X_test)\n",
    "y_prob = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# 6.3 Evaluering/Resultat\n",
    "print(\"\\nEvaluering – Random Forest\")\n",
    "print(\"Accuracy :\", round(accuracy_score(y_test, y_pred), 3))\n",
    "print(\"Precision:\", round(precision_score(y_test, y_pred), 3))\n",
    "print(\"Recall   :\", round(recall_score(y_test, y_pred), 3))\n",
    "print(\"F1-score :\", round(f1_score(y_test, y_pred), 3))\n",
    "print(\"ROC-AUC  :\", round(roc_auc_score(y_test, y_prob), 3))\n",
    "\n",
    "# 6.4 Matrise\n",
    "print(\"\\nConfusion matrix (TN, FP; FN, TP):\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ],
   "id": "3d7cf054be6cd383",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 14\u001B[39m\n\u001B[32m      6\u001B[39m \u001B[38;5;66;03m# 6.1 Trening\u001B[39;00m\n\u001B[32m      7\u001B[39m rf = RandomForestClassifier(\n\u001B[32m      8\u001B[39m     n_estimators=\u001B[32m100\u001B[39m,\n\u001B[32m      9\u001B[39m     class_weight=\u001B[33m'\u001B[39m\u001B[33mbalanced_subsample\u001B[39m\u001B[33m'\u001B[39m,\n\u001B[32m     10\u001B[39m     random_state=\u001B[32m42\u001B[39m,\n\u001B[32m     11\u001B[39m     n_jobs=-\u001B[32m1\u001B[39m \n\u001B[32m     12\u001B[39m )\n\u001B[32m---> \u001B[39m\u001B[32m14\u001B[39m rf.fit(\u001B[43mX_train\u001B[49m, y_train)\n\u001B[32m     16\u001B[39m \u001B[38;5;66;03m# 6.2 Prediksjon\u001B[39;00m\n\u001B[32m     17\u001B[39m y_pred = rf.predict(X_test)\n",
      "\u001B[31mNameError\u001B[39m: name 'X_train' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 7 DISKUSJON\n",
    "\n",
    "### Evaluering - Logistisk reggresjon\n",
    "Accuracy : 0.899\n",
    "Precision: 0.486\n",
    "Recall   : 0.927\n",
    "F1-score : 0.638\n",
    "ROC-AUC  : 0.965\n",
    "\n",
    "Confusion matrix (TN, FP; FN, TP):\n",
    "[[810  94]\n",
    " [  7  89]]\n",
    " \n",
    "### Evaluering – Random Forest\n",
    "Accuracy : 0.99\n",
    "Precision: 0.957\n",
    "Recall   : 0.938\n",
    "F1-score : 0.947\n",
    "ROC-AUC  : 0.998\n",
    "\n",
    "Confusion matrix (TN, FP; FN, TP):\n",
    "[[900   4]\n",
    " [  6  90]]\n",
    " \n",
    "### Hvem gjør best?\n",
    "Random Forest vinner på alle målene. Logistisk regresjon har også bra resultater, men har lav presisjon. Dette vil si at den nesten finner alle \"ja\" utfallene, men kommer ofte med FP og sier \"ja\" når svaret egt er nei. På FN så er resultatene like mellom modellene, men på den FP så gjorde Random forest det 95% bedre. \n",
    "\n",
    "### Hvorfor?\n",
    "Jeg tenkte at hver faktor alene spiller en rolle på om en person får lån eller ikke, men da RF hadde bedre resultater, vil jeg annta at det er sammenhenger mellom faktorene som RF klarte å plukke opp på som LR ikke klarte. Jeg vil fortsatt si at RF gjorde det bedre nå enn det et vanlig tre hadde gjort, da den tar bedre hennsyn til denne ubalansen mellom ja og nei. og LR er fortsatt en relativt god modell med gode tall, men den er langt nær like god som RF. \n",
    "\n",
    "### Tidlige valg\n",
    "Sjekken av dataene gikk fint, så det ble ikke gjort noen endirnger i forhold til dem. Om det hadde blitt gjort endirnger, så vil jeg tro at disse, sammen med endringene om å fjerne 2 ikke nødvendige felter, kun gjorde modellene bedre da de mer sannsynlig fjernet støy. Det jeg kommer på som eventuellt kunne hatt noe å si er ZIP, hvor det er mulig at det har noen sammenheng, men når jeg kjørte samme kode med ZIP inne i datasettet, forble resultatet uendret, som vil si at for denne oppgaven så hadde det ingenting å si. \n",
    "\n"
   ],
   "id": "45c3ac96fc797cda"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
